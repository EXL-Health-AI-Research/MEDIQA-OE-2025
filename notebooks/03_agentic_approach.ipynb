{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96ffd080",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8478a18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7490abb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from load_dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971bc2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhinand/dev/work-research/MEDIQA-OE-2025/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "from IPython.display import Markdown\n",
    "from loguru import logger\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "from mediqa_oe.data import MedicalOrderDataLoader\n",
    "from mediqa_oe.lm import OrderExtractionLM\n",
    "from mediqa_oe.lm.base import BaseAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d551a5",
   "metadata": {},
   "source": [
    "## Load Data and LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4960d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TranscriptTurn:\n",
    "    turn_id: int\n",
    "    speaker: str\n",
    "    transcript: str\n",
    "\n",
    "@dataclass\n",
    "class MedicalOrder:\n",
    "    order_type: str\n",
    "    description: str\n",
    "    reason: str\n",
    "    provenance: List[int]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7480eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_json_path = '<input_json_path for test>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0271f8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = MedicalOrderDataLoader(trs_json_path=\"../data/orders_data_transcript.json\")\n",
    "\n",
    "ds, ds_val = data_loader.ds, data_loader.ds_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9395ef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = OrderExtractionLM(\n",
    "    backend=\"openai\",\n",
    "    model_name_or_path=\"\",\n",
    "    api_base=os.getenv(\"OPENAI_API_BASE\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab72c87",
   "metadata": {},
   "source": [
    "## Methods Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3ab3369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['google/medgemma-27b-text-it']\n"
     ]
    }
   ],
   "source": [
    "print([model.id for model in lm.impl.client.models.list().data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaeb973d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Remote: https://e307wui0v6xrqf-8000.proxy.runpod.net/v1/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.get_device_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6ad907c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I am a medical AI assistant designed to provide concise, one-sentence answers to health-related questions.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_msg = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a medical AI assistant how answers in one sentence.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hi, what kind of assistant are you?\",\n",
    "    },\n",
    "]\n",
    "\n",
    "out = lm.infer(\n",
    "    messages=test_msg\n",
    ")\n",
    "\n",
    "Markdown(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c85a546a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a medical AI assistant designed to provide information and answer questions related to health and medicine in a single sentence.\n"
     ]
    }
   ],
   "source": [
    "for chunk in lm.infer_stream(messages=test_msg):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ba78b0",
   "metadata": {},
   "source": [
    "## Agentic Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d3a142",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent1_Extractor(BaseAgent):\n",
    "    \"\"\"Agent 1: Extract descriptions and reasons from clinical transcripts\"\"\"\n",
    "\n",
    "    def process(self, transcript: List[TranscriptTurn]) -> Tuple[Dict[int, List[str]], Dict[int, List[str]]]:\n",
    "        \"\"\"Extract medical descriptions and reasons from transcript\"\"\"\n",
    "\n",
    "        system_prompt = \"\"\"\n",
    "                    You are a clinically trained assistant tasked with extracting only *precise, actionable medical orders* and their justifying reasons from a clinical conversation.\n",
    "\n",
    "                    Your goal is to extract:\n",
    "\n",
    "                    1. DESCRIPTIONS: Only *clear, clinically actionable medical orders* related to:\n",
    "                    - Medications (e.g., \"start metformin\", \"continue omeprazole 20 milligrams daily\")\n",
    "                    - Lab tests (e.g., \"order a hemoglobin a1c\", \"check white blood cell count\")\n",
    "                    - Imaging studies (e.g., \"schedule a chest x-ray\", \"get an MRI of the brain\")\n",
    "                    - Follow-ups or Referrals (e.g., \"see endocrinologist\", \"come back in 2 weeks\")\n",
    "\n",
    "                    2. REASONS: Only *clinically meaningful problems, diagnoses, or symptoms* that clearly explain why the above order is needed (e.g., \"for diabetes\", \"due to shortness of breath\")\n",
    "\n",
    "                    ---\n",
    "\n",
    "                    ðŸ”’ STRICT RULES (DO NOT VIOLATE):\n",
    "                    - âŒ DO NOT extract vague suggestions (\"weigh yourself\", \"call me\", \"go to the ER\")\n",
    "                    - âŒ DO NOT extract non-actionable observations or physical findings (\"vital signs\", \"crackles\", \"edema\", \"murmur\", \"exam looks good\")\n",
    "                    - âŒ DO NOT include commands to medical staff (\"show me labs\", \"pull up x-ray\")\n",
    "                    - âœ… ONLY extract direct clinical actions involving patient care\n",
    "                    - âœ… EXTRACT ONLY 10 DESCRIPTION AND REASON PER TURN\n",
    "\n",
    "                    ---\n",
    "\n",
    "                    ðŸ§  SELF-CHECK:\n",
    "                    - âœ… Is the phrase a *clear medical order* related to drugs, labs, imaging, or follow-up?\n",
    "                    - âœ… Is the reason a *disease, symptom, or clinical condition* directly tied to the action?\n",
    "                    - âŒ If unsure or borderline â€” DO NOT extract it.\n",
    "\n",
    "                    ---\n",
    "\n",
    "                    ðŸ” FORMAT:\n",
    "                    Return a single *valid JSON object*:\n",
    "                    {\n",
    "                    \"descriptions\": [list of exact phrases, each â‰¤30 tokens],\n",
    "                    \"reasons\": [list of exact phrases, each â‰¤30 tokens]\n",
    "                    }\n",
    "\n",
    "                    ---\n",
    "\n",
    "                    âœ… GOOD EXAMPLES (KEEP):\n",
    "                    \"order a hemoglobin a1c\"\n",
    "                    \"put you on some lasix 40 milligrams a day\"\n",
    "                    \"continue you on the omeprazole 20 milligrams a day\"\n",
    "                    \"refer you to psychiatry\"\n",
    "                    \"follow up with your endocrinologist\"\n",
    "                    \"for your type i diabetes\"\n",
    "                    \"due to acute heart failure exacerbation\"\n",
    "\n",
    "                    âŒ BAD EXAMPLES (REMOVE):\n",
    "                    \"show me the vital signs\"\n",
    "                    \"labs look okay\"\n",
    "                    \"oxygenation level\"\n",
    "                    \"reviewed the results\"\n",
    "                    \"weigh yourself every day\"\n",
    "                    \"call 911\"\n",
    "                    \"neck exam\"\n",
    "                    \"it looks good\"\n",
    "                    \"pulse ox\"\n",
    "\n",
    "                    ---\n",
    "\n",
    "                    ðŸ“Œ Final reminder:\n",
    "                    Only return *fully valid, concise, medically actionable JSON. If there is **nothing valid*, return:\n",
    "                    {\"descriptions\": [], \"reasons\": []}\n",
    "             \"\"\"\n",
    "\n",
    "\n",
    "        description_dict = {}\n",
    "        reason_dict = {}\n",
    "\n",
    "        for turn in transcript:\n",
    "            # Focus on medically relevant speakers\n",
    "            if turn.speaker in [\"DOCTOR\"]:\n",
    "                user_input = f\"\"\"Turn {turn.turn_id}: \"{turn.transcript}\"\n",
    "\n",
    "                # Extract medical descriptions and reasons from this turn. Return only JSON:\n",
    "                # {{\"descriptions\": [\"exact phrase 1\", \"exact phrase 2\"], \"reasons\": [\"reason 1\", \"reason 2\"]}}\"\"\"\n",
    "\n",
    "                messages = self._create_messages(system_prompt, user_input)\n",
    "                response = self.llm.infer(messages, max_new_tokens=500)\n",
    "\n",
    "                if response:\n",
    "                    try:\n",
    "                        # Clean response to extract JSON\n",
    "                        json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "                        if json_match:\n",
    "                            parsed = json.loads(json_match.group())\n",
    "                            if parsed.get(\"descriptions\"):\n",
    "                                description_dict[turn.turn_id] = parsed[\"descriptions\"]\n",
    "                            if parsed.get(\"reasons\"):\n",
    "                                reason_dict[turn.turn_id] = parsed[\"reasons\"]\n",
    "                    except json.JSONDecodeError:\n",
    "                        # Fallback parsing if JSON fails\n",
    "                        descriptions = self._extract_with_regex(turn.transcript, \"description\")\n",
    "                        reasons = self._extract_with_regex(turn.transcript, \"reason\")\n",
    "                        if descriptions:\n",
    "                            description_dict[turn.turn_id] = descriptions\n",
    "                        if reasons:\n",
    "                            reason_dict[turn.turn_id] = reasons\n",
    "\n",
    "        return description_dict, reason_dict\n",
    "\n",
    "    def _extract_with_regex(self, text: str, extract_type: str) -> List[str]:\n",
    "        \"\"\"Fallback regex extraction if LLM fails\"\"\"\n",
    "        if extract_type == \"description\":\n",
    "            patterns = [\n",
    "                r'(?:order|prescribe|schedule|book|perform|do|give|take)\\s+([^.!?]{10,100})',\n",
    "                r'(?:need|want|should|will)\\s+(?:to\\s+)?([^.!?]{10,100})',\n",
    "                r'(?:let\\'s|we\\'ll)\\s+([^.!?]{10,100})'\n",
    "            ]\n",
    "        else:  # reason\n",
    "            patterns = [\n",
    "                r'(?:for|due to|because of|to treat|regarding)\\s+([^.!?]{10,100})',\n",
    "                r'(?:pain|symptoms?|condition|problem|difficulty|trouble)\\s+([^.!?]{10,100})'\n",
    "            ]\n",
    "\n",
    "        results = []\n",
    "        for pattern in patterns:\n",
    "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "            results.extend([match.strip() for match in matches if len(match.strip()) > 5])\n",
    "\n",
    "        return results[:3]  # Limit to 3 per turn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c359037",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent2_Mapper(BaseAgent):\n",
    "    \"\"\"Agent 2: Map descriptions to reasons using transcript context\"\"\"\n",
    "\n",
    "    def process(self, description_dict: Dict[int, List[str]], reason_dict: Dict[int, List[str]],\n",
    "                transcript: List[TranscriptTurn]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Map descriptions to reasons using clinical context and transcript\"\"\"\n",
    "\n",
    "        system_prompt = \"\"\"\n",
    "\n",
    "                You are a clinical expert validating the correctness of mappings between medical orders (\"descriptions\") and clinical justifications (\"reasons\") using the actual doctor-patient transcript.\n",
    "\n",
    "                You are given:\n",
    "                - A list of mappings: [{\"description\": ..., \"reason\": ..., \"provenance\": [turn_ids]}]\n",
    "                - A full transcript: [{\"turn_id\": ..., \"speaker\": ..., \"transcript\": ...}, ...]\n",
    "\n",
    "                Your job is to strictly verify each mapping.\n",
    "\n",
    "                For each mapping:\n",
    "                1. âœ… The *description* must be a real, actionable clinical order clearly stated in one of the provenance turns. Examples: prescribing a medication, ordering a test, requesting follow-up, imaging, or referral.\n",
    "                2. âœ… The *reason* must be a clearly stated clinical problem, symptom, or diagnosis â€” also found within the provenance turns or in immediately adjacent context.\n",
    "                3. âœ… The *provenance* must include turn IDs where both description and reason are mentioned or inferred from context.\n",
    "                4. âœ… The mapping must be *clinically logical* â€” would a real doctor give that order for that reason?\n",
    "\n",
    "                Strict Rejection Rules:\n",
    "                - âŒ Reject mappings if description is vague or general (e.g., \"labs look okay\", \"exam\", \"oxygenation level\")\n",
    "                - âŒ Reject mappings if the reason is unclear, non-clinical, or just an observation (e.g., \"pulse ox\", \"reviewed x-ray\")\n",
    "                - âŒ Reject if either description or reason does NOT appear in the provenance\n",
    "                - âŒ Reject hallucinated or inferred phrases that are not clearly spoken in transcript\n",
    "\n",
    "                Format of Your Output:\n",
    "                Return a single valid JSON array of corrected and verified mappings only:\n",
    "                [\n",
    "                {\n",
    "                    \"description\": \"verified description from transcript\",\n",
    "                    \"reason\": \"verified clinical reason from transcript or empty string\",\n",
    "                    \"provenance\": [verified_turn_ids]\n",
    "                },\n",
    "                ...\n",
    "                ]\n",
    "\n",
    "                If a mapping is not fully valid based on the transcript, DO NOT include it in the output.\n",
    "\n",
    "                âœ… Examples of accepted output:\n",
    "                [\n",
    "                {\n",
    "                    \"description\": \"put you on some lasix 40 milligrams a day\",\n",
    "                    \"reason\": \"acute heart failure exacerbation\",\n",
    "                    \"provenance\": [125, 126, 127]\n",
    "                },\n",
    "                {\n",
    "                    \"description\": \"order a hemoglobin a1c\",\n",
    "                    \"reason\": \"type i diabetes\",\n",
    "                    \"provenance\": [138, 139]\n",
    "                }\n",
    "                ]\n",
    "\n",
    "                Final Reminders:\n",
    "                - Be strict. Do NOT let vague, non-actionable, or unrelated mappings through.\n",
    "                - Do NOT invent or hallucinate content.\n",
    "                - ONLY include verified mappings grounded in the transcript and supported clinically.\n",
    "                \"\"\"\n",
    "\n",
    "        # Build context from transcript\n",
    "        transcript_context = []\n",
    "        for turn in transcript:\n",
    "            transcript_context.append(f\"Turn {turn.turn_id} ({turn.speaker}): {turn.transcript}\")\n",
    "\n",
    "        # Prepare structured input\n",
    "        all_descriptions = []\n",
    "        all_reasons = []\n",
    "\n",
    "        for turn_id, descriptions in description_dict.items():\n",
    "            for desc in descriptions:\n",
    "                all_descriptions.append({\"turn_id\": turn_id, \"text\": desc})\n",
    "\n",
    "        for turn_id, reasons in reason_dict.items():\n",
    "            for reason in reasons:\n",
    "                all_reasons.append({\"turn_id\": turn_id, \"text\": reason})\n",
    "\n",
    "        user_input = f\"\"\"TRANSCRIPT CONTEXT:\n",
    "                    {chr(10).join(transcript_context)}\n",
    "\n",
    "                    EXTRACTED DESCRIPTIONS:\n",
    "                    {json.dumps(all_descriptions, indent=2)}\n",
    "\n",
    "                    EXTRACTED REASONS:\n",
    "                    {json.dumps(all_reasons, indent=2)}\n",
    "\n",
    "                    Map each description to the most clinically relevant reason using the full conversation context.\n",
    "                    Look for patterns where patient mentions symptoms/conditions and doctor responds with orders.\n",
    "                    Return JSON array only:\n",
    "                    [{{\"description\": \"exact text\", \"reason\": \"exact text or empty\", \"provenance\": [turn_ids]}}]\n",
    "                \"\"\"\n",
    "\n",
    "        messages = self._create_messages(system_prompt, user_input)\n",
    "        response = self.llm.infer(messages, max_new_tokens=2000)\n",
    "\n",
    "        if response:\n",
    "            try:\n",
    "                # Extract JSON from response\n",
    "                json_match = re.search(r'\\[.*\\]', response, re.DOTALL)\n",
    "                if json_match:\n",
    "                    return json.loads(json_match.group())\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "\n",
    "        # Fallback: context-aware mapping\n",
    "        return self._fallback_mapping(description_dict, reason_dict, transcript)\n",
    "\n",
    "    def _fallback_mapping(self, description_dict: Dict[int, List[str]],\n",
    "                         reason_dict: Dict[int, List[str]],\n",
    "                         transcript: List[TranscriptTurn]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Context-aware fallback mapping using transcript flow\"\"\"\n",
    "        mappings = []\n",
    "\n",
    "        # Create turn lookup\n",
    "        turn_lookup = {turn.turn_id: turn for turn in transcript}\n",
    "\n",
    "        for desc_turn, descriptions in description_dict.items():\n",
    "            for desc in descriptions:\n",
    "                best_reason = \"\"\n",
    "                best_turn = None\n",
    "                best_score = 0\n",
    "\n",
    "                # Look for reasons in nearby turns, prioritizing patient statements\n",
    "                for reason_turn, reasons in reason_dict.items():\n",
    "                    for reason in reasons:\n",
    "                        score = self._calculate_mapping_score(\n",
    "                            desc_turn, reason_turn, desc, reason, turn_lookup\n",
    "                        )\n",
    "                        if score > best_score:\n",
    "                            best_score = score\n",
    "                            best_reason = reason\n",
    "                            best_turn = reason_turn\n",
    "\n",
    "                provenance = [desc_turn]\n",
    "                if best_turn and best_turn != desc_turn:\n",
    "                    provenance.append(best_turn)\n",
    "\n",
    "                mappings.append({\n",
    "                    \"description\": desc,\n",
    "                    \"reason\": best_reason,\n",
    "                    \"provenance\": sorted(provenance)\n",
    "                })\n",
    "\n",
    "        return mappings\n",
    "\n",
    "    def _calculate_mapping_score(self, desc_turn: int, reason_turn: int,\n",
    "                               desc: str, reason: str, turn_lookup: Dict[int, TranscriptTurn]) -> float:\n",
    "        \"\"\"Calculate mapping score based on context\"\"\"\n",
    "        score = 0\n",
    "\n",
    "        # Distance penalty (closer turns get higher score)\n",
    "        distance = abs(desc_turn - reason_turn)\n",
    "        distance_score = max(0, 10 - distance)\n",
    "        score += distance_score\n",
    "\n",
    "        # Patient-to-doctor flow bonus\n",
    "        if (reason_turn < desc_turn and\n",
    "            turn_lookup.get(reason_turn, {}).speaker == \"PATIENT\" and\n",
    "            turn_lookup.get(desc_turn, {}).speaker in [\"DOCTOR\", \"PHYSICIAN\"]):\n",
    "            score += 5\n",
    "\n",
    "        # Semantic similarity bonus (basic keyword matching)\n",
    "        desc_words = set(desc.lower().split())\n",
    "        reason_words = set(reason.lower().split())\n",
    "        common_words = desc_words.intersection(reason_words)\n",
    "        score += len(common_words) * 2\n",
    "\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549e123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent3_Classifier(BaseAgent):\n",
    "    \"\"\"Agent 3: Classify orders into types (medication, lab, imaging, followup)\"\"\"\n",
    "\n",
    "    def process(self, mapped_pairs: List[Dict[str, Any]]) -> List[MedicalOrder]:\n",
    "        \"\"\"Classify each description-reason pair into order types\"\"\"\n",
    "\n",
    "        system_prompt = \"\"\"You are a medical expert classifying orders into types.\n",
    "                        Categories:\n",
    "                        - medication: Drugs, prescriptions, dosages, pharmacy instructions\n",
    "                        - lab: Blood tests, A1C, screenings, examinations, diagnostic tests\n",
    "                        - imaging: X-rays, CT, MRI, ultrasound scans, radiological studies\n",
    "                        - followup: Referrals, appointments, return visits, scheduling\n",
    "\n",
    "                        Rules:\n",
    "                        - Use clinical intent, not just keywords\n",
    "                        - Each order gets exactly one type\n",
    "                        - Maintain original description and reason text\n",
    "                        - Return valid JSON array only: [{\"order_type\": \"...\", \"description\": \"...\", \"reason\": \"...\", \"provenance\": [...]}]\"\"\"\n",
    "\n",
    "\n",
    "        user_input = f\"\"\"Classify these medical orders:\n",
    "                        {json.dumps(mapped_pairs, indent=2)}\n",
    "                        Return JSON array with order_type added to each item:\n",
    "                        [{{\"order_type\": \"medication|lab|imaging|followup\", \"description\": \"...\", \"reason\": \"...\", \"provenance\": [...]}}]\"\"\"\n",
    "\n",
    "        messages = self._create_messages(system_prompt, user_input)\n",
    "        response = self.llm.infer(messages, max_new_tokens=2000)\n",
    "\n",
    "        if response:\n",
    "            try:\n",
    "                # Extract JSON from response\n",
    "                json_match = re.search(r'\\[.*\\]', response, re.DOTALL)\n",
    "                if json_match:\n",
    "                    classified = json.loads(json_match.group())\n",
    "                    return [MedicalOrder(**order) for order in classified]\n",
    "            except (json.JSONDecodeError, TypeError):\n",
    "                pass\n",
    "\n",
    "        # Fallback classification\n",
    "        return self._fallback_classification(mapped_pairs)\n",
    "\n",
    "    def _fallback_classification(self, mapped_pairs: List[Dict[str, Any]]) -> List[MedicalOrder]:\n",
    "        \"\"\"Rule-based fallback classification\"\"\"\n",
    "        orders = []\n",
    "\n",
    "        classification_patterns = {\n",
    "            'medication': [\n",
    "                'medication', 'prescription', 'dose', 'mg', 'pills', 'tablet', 'capsule',\n",
    "                'drug', 'pharmacy', 'take', 'prescribe', 'antibiotic', 'pain relief'\n",
    "            ],\n",
    "            'lab': [\n",
    "                'blood', 'test', 'a1c', 'screening', 'examination', 'lab', 'sample',\n",
    "                'otoscopy', 'urine', 'stool', 'culture', 'panel', 'workup'\n",
    "            ],\n",
    "            'imaging': [\n",
    "                'x-ray', 'ct', 'mri', 'ultrasound', 'scan', 'imaging', 'radiology',\n",
    "                'mammogram', 'echo', 'nuclear', 'pet'\n",
    "            ],\n",
    "            'followup': [\n",
    "                'follow-up', 'appointment', 'visit', 'come back', 'schedule', 'return',\n",
    "                'referral', 'see', 'consult', 'specialist'\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        for pair in mapped_pairs:\n",
    "            text = f\"{pair['description']} {pair['reason']}\".lower()\n",
    "\n",
    "            # Score each category\n",
    "            scores = {}\n",
    "            for category, patterns in classification_patterns.items():\n",
    "                scores[category] = sum(1 for pattern in patterns if pattern in text)\n",
    "\n",
    "            # Choose category with highest score\n",
    "            order_type = max(scores, key=scores.get) if max(scores.values()) > 0 else 'followup'\n",
    "\n",
    "            orders.append(MedicalOrder(\n",
    "                order_type=order_type,\n",
    "                description=pair['description'],\n",
    "                reason=pair['reason'],\n",
    "                provenance=pair['provenance']\n",
    "            ))\n",
    "\n",
    "        return orders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16dd791",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent4_Validator(BaseAgent):\n",
    "    \"\"\"Agent 4: Validate and format final output\"\"\"\n",
    "\n",
    "    def process(self, classified_orders: List[MedicalOrder]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Validate medical orders and format final output\"\"\"\n",
    "\n",
    "        system_prompt = \"\"\"You are a clinical validation expert tasked with reviewing a list of extracted medical orders from a doctor-patient conversation.\n",
    "\n",
    "                    Each order includes:\n",
    "                    - \"order_type\": The general clinical category of the order (e.g., medication, lab, imaging, follow-up)\n",
    "                    - \"description\": A specific, actionable medical instruction (e.g., \"start you on metformin\", \"order a hemoglobin a1c\")\n",
    "                    - \"reason\": A clinical justification for the order (e.g., \"type i diabetes\", \"shortness of breath\")\n",
    "                    - \"provenance\": A list of transcript turn IDs where the description and/or reason were spoken\n",
    "\n",
    "                    ---\n",
    "\n",
    "                    Your job is to *strictly validate* each entry based on the following criteria:\n",
    "\n",
    "                    ### âœ… VALIDATION CRITERIA\n",
    "\n",
    "                    1. *Description Quality*\n",
    "                    - Must be a *clear, specific, and actionable medical order*\n",
    "                    - âŒ Reject vague or generic statements like \"labs look good\", \"check your vitals\", \"follow up\"\n",
    "                    - âœ… Must reflect real medical decision-making (e.g., drug initiation, lab/imaging request, follow-up instructions)\n",
    "\n",
    "                    2. *Clinical Logic*\n",
    "                    - The *order_type, **description, and **reason* must be *clinically consistent and meaningful together*\n",
    "                    - Example:\n",
    "                        - âœ… \"order_type\": \"lab\", \"description\": \"order a hemoglobin a1c\", \"reason\": \"type i diabetes\"\n",
    "                        - âŒ \"order_type\": \"imaging\", \"description\": \"get an x-ray\", \"reason\": \"depression\"\n",
    "\n",
    "                    3. *No Duplication*\n",
    "                    - Remove duplicate or near-duplicate orders (e.g., â€œorder hemoglobin a1câ€ and â€œcheck a1câ€ in same context)\n",
    "                    - Keep only the most precise or complete phrasing\n",
    "\n",
    "                    4. *Safety and Appropriateness*\n",
    "                    - Reject orders that are medically unsafe, contradictory, or do not make sense for the stated reason\n",
    "                    - âŒ Examples: \"give insulin\" for \"depression\", or \"refer to psychiatry\" for \"abdominal pain\"\n",
    "\n",
    "                    ---\n",
    "\n",
    "                    ### âš  STRICT RULES\n",
    "\n",
    "                    - âŒ Do NOT invent or change any values\n",
    "                    - âŒ Do NOT create new orders\n",
    "                    - âœ… ONLY remove invalid or weak entries\n",
    "                    - âœ… Preserve the exact wording of description, reason, and order_type for valid items\n",
    "\n",
    "                    ---\n",
    "\n",
    "                    ### âœ… OUTPUT FORMAT\n",
    "\n",
    "                    Return a *valid JSON array* of cleaned, verified orders:\n",
    "\n",
    "                    ```json\n",
    "                    [\n",
    "                    {\n",
    "                        \"order_type\": \"medication\",\n",
    "                        \"description\": \"put you on some lasix 40 milligrams a day\",\n",
    "                        \"reason\": \"acute heart failure exacerbation\",\n",
    "                        \"provenance\": [125, 126, 127]\n",
    "                    },\n",
    "                    {\n",
    "                        \"order_type\": \"lab\",\n",
    "                        \"description\": \"order a hemoglobin a1c\",\n",
    "                        \"reason\": \"type i diabetes\",\n",
    "                        \"provenance\": [138, 139]\n",
    "                    }\n",
    "                    ]\n",
    "\"\"\"\n",
    "\n",
    "        orders_json = [\n",
    "            {\n",
    "                \"order_type\": order.order_type,\n",
    "                \"description\": order.description,\n",
    "                \"reason\": order.reason,\n",
    "                \"provenance\": order.provenance\n",
    "            }\n",
    "            for order in classified_orders\n",
    "        ]\n",
    "\n",
    "        user_input = f\"\"\"Validate these medical orders:\n",
    "                {json.dumps(orders_json, indent=2)}\n",
    "                Remove any invalid orders and return the cleaned JSON array:\n",
    "                [{{\"order_type\": \"...\", \"description\": \"...\", \"reason\": \"...\", \"provenance\": [...]}}]\"\"\"\n",
    "\n",
    "        messages = self._create_messages(system_prompt, user_input)\n",
    "        response = self.llm.infer(messages, max_new_tokens=2000)\n",
    "\n",
    "        if response:\n",
    "            try:\n",
    "                # Extract JSON from response\n",
    "                json_match = re.search(r'\\[.*\\]', response, re.DOTALL)\n",
    "                if json_match:\n",
    "                    return json.loads(json_match.group())\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "\n",
    "        # Fallback validation\n",
    "        return self._fallback_validation(orders_json)\n",
    "\n",
    "    def _fallback_validation(self, orders: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Basic validation rules\"\"\"\n",
    "        valid_orders = []\n",
    "        seen_orders = set()\n",
    "\n",
    "        for order in orders:\n",
    "            # Skip vague or too short descriptions\n",
    "            if len(order['description'].strip()) < 10:\n",
    "                continue\n",
    "\n",
    "            # Skip if no meaningful provenance\n",
    "            if not order['provenance']:\n",
    "                continue\n",
    "\n",
    "            # Remove duplicates\n",
    "            order_key = (order['description'].lower(), order['reason'].lower())\n",
    "            if order_key in seen_orders:\n",
    "                continue\n",
    "            seen_orders.add(order_key)\n",
    "\n",
    "            # Basic medical logic checks\n",
    "            if self._is_medically_logical(order):\n",
    "                valid_orders.append(order)\n",
    "\n",
    "        return valid_orders\n",
    "\n",
    "    def _is_medically_logical(self, order: Dict[str, Any]) -> bool:\n",
    "        \"\"\"Basic medical logic validation\"\"\"\n",
    "        desc = order['description'].lower()\n",
    "        reason = order['reason'].lower()\n",
    "\n",
    "        # Basic illogical combinations\n",
    "        illogical_pairs = [\n",
    "            ('x-ray', 'headache'),  # unless trauma mentioned\n",
    "            ('blood test', 'broken bone'),\n",
    "            ('antibiotic', 'viral infection')\n",
    "        ]\n",
    "\n",
    "        for desc_pattern, reason_pattern in illogical_pairs:\n",
    "            if desc_pattern in desc and reason_pattern in reason:\n",
    "                if desc_pattern == 'x-ray' and 'trauma' in reason:\n",
    "                    continue  # This is actually logical\n",
    "                return False\n",
    "\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c33774",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedicalOrderExtractor:\n",
    "    \"\"\"Main pipeline orchestrator\"\"\"\n",
    "\n",
    "    def __init__(self, llm: OrderExtractionLM):\n",
    "        self.llm = llm\n",
    "        self.agent1 = Agent1_Extractor(llm)\n",
    "        self.agent2 = Agent2_Mapper(llm)\n",
    "        self.agent3 = Agent3_Classifier(llm)\n",
    "        self.agent4 = Agent4_Validator(llm)\n",
    "\n",
    "    def extract_orders(self, transcript_data: Dict[str, Any]) -> Dict[str, List[Dict[str, Any]]]:\n",
    "        \"\"\"Main extraction pipeline\"\"\"\n",
    "\n",
    "        # Parse input\n",
    "        conversation_id = transcript_data[\"id\"]\n",
    "        transcript = [TranscriptTurn(**turn) for turn in transcript_data[\"transcript\"]]\n",
    "\n",
    "        logger.info(f\"Processing conversation: {conversation_id}\")\n",
    "\n",
    "        # Agent 1: Extract descriptions and reasons\n",
    "        logger.info(\"Agent 1: Extracting descriptions and reasons...\")\n",
    "        description_dict, reason_dict = self.agent1.process(transcript)\n",
    "        logger.info(f\"Found {len(description_dict)} description turns, {len(reason_dict)} reason turns\")\n",
    "        logger.info(f\"description_dict-->{description_dict}\")\n",
    "        logger.info(f\"reason_dict-->{reason_dict}\")\n",
    "\n",
    "\n",
    "        # Agent 2: Map descriptions to reasons using transcript context\n",
    "        logger.info(\"Agent 2: Mapping descriptions to reasons with transcript context...\")\n",
    "        mapped_pairs = self.agent2.process(description_dict, reason_dict, transcript)\n",
    "        logger.info(f\"Created {len(mapped_pairs)} description-reason pairs\")\n",
    "        logger.info(f\"mapped_pairs-->{mapped_pairs}\")\n",
    "\n",
    "        # Agent 3: Classify order types\n",
    "        logger.info(\"Agent 3: Classifying order types...\")\n",
    "        classified_orders = self.agent3.process(mapped_pairs)\n",
    "        logger.info(f\"Classified {len(classified_orders)} orders\")\n",
    "        logger.info(f\"classified_orders-->{classified_orders}\")\n",
    "\n",
    "\n",
    "        # Agent 4: Validate and format\n",
    "        logger.info(\"Agent 4: Validating and formatting...\")\n",
    "        final_orders = self.agent4.process(classified_orders)\n",
    "        logger.info(f\"Final output: {len(final_orders)} valid orders\")\n",
    "\n",
    "        return {conversation_id: final_orders}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a71bc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize data loader\n",
    "    data_loader = MedicalOrderDataLoader(input_json_path)\n",
    "    ds, ds_val = data_loader.ds, data_loader.ds_val\n",
    "\n",
    "    dic={}\n",
    "    for i in ds_val:\n",
    "        if i['id']==\"primock57_3_3\":\n",
    "            dic[\"id\"] = i['id']\n",
    "            dic['expected_orders'] = i['expected_orders']\n",
    "            dic['transcript'] = i['transcript']\n",
    "\n",
    "    \n",
    "    # Initialize extractor\n",
    "    extractor = MedicalOrderExtractor(lm)\n",
    "\n",
    "\n",
    "\n",
    "    final_results = []\n",
    "    for sample in ds_val:\n",
    "        results = extractor.extract_orders(sample)\n",
    "        final_results.append(results)\n",
    "\n",
    "\n",
    "    print(\"\\nFinal Results:\")\n",
    "    print(json.dumps(final_results, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
