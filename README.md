# MEDIQA-OE-2025

**Medical Order Extraction using MedGemma 27B + vLLM on RunPod**

This repository demonstrates multiple approaches for medical order extraction from clinical conversations as part of **MEDIQA-OE-2025**. We deploy **MedGemma-27B** on **RunPod** using **vLLM**, expose an OpenAI-compatible API, and run experiments via structured notebooks.

---

## âœ… Key Features
- **RunPod + vLLM** for scalable MedGemma deployment
- **OpenAI-compatible API** for inference
- Multiple approaches:
  - **Few-Shot Prompting**
  - **ReAct Reasoning**
  - **Agent Prompting**
- Organized **notebooks** and **prompt templates**

## ðŸ“‚ Repository Layout

MEDIQA-OE-2025/
â”‚
â”œâ”€â”€ src/mediqa_oe/                     # Python package for core logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data.py               # API call logic to vLLM server
â”‚   â””â”€â”€ lm
â”‚        â”œâ”€â”€__init__.py
â”‚        â”œâ”€â”€ base.py
â”‚        â””â”€â”€ model.py              
â”‚
â”œâ”€â”€ notebooks/                     # Organized by approach
â”‚   â”œâ”€â”€ .env.template
â”‚   â”œâ”€â”€ 01_zero_shot.ipynb         # Zero-shot approach
â”‚   â”œâ”€â”€ 02_few_shot.ipynb          # Few-shot prompt experiments
â”‚   â”œâ”€â”€ 03_react_agent.ipynb       # ReAct-based approach
â”‚   
â”œâ”€â”€ main.py
â”œâ”€â”€ pyproject.toml                 # Dependency config
â”œâ”€â”€ README.md                      # Main documentation
â””â”€â”€ uv.lock

## ðŸ”§ Installation

### **1. Clone Repository**
```bash
git clone https://github.com/EXL-Health-AI-Research/MEDIQA-OE-2025.git
cd MEDIQA-OE-2025
```

### **2. Install Dependices**
```bash
pip install .
```
## Deploying vLLM on RunPod with MedGemma 27B

### **1. Start the Pod**

* Sign in to RunPod
* Launch a Custom Pod with:
    - **Image**: runpod/vllm-openai:latest
    -**GPU**: 2 A10 GPUs 48 vRAM 9 vCPU
    -**Disk**: â‰¥ 80GB
* Attach your Hugging Face token for gated models


### **2. Run the vLLM API Server**
 
Inside the container, execute:
```bash
--host 0.0.0.0 --port 8000 --model google/medgemma-27b-text-it --dtype bfloat16 --gpu-memory-utilization 0.98 --api-key <API-KEY>--max-model-len 24768 --tensor-parallel-size 2 --seed 1337Â --enforce-eager
```

## âœ… Using Notebooks
* notebooks/01_few_shot.ipynb â†’ Few-shot Prompting
* notebooks/02_react_reasoning.ipynb â†’ ReAct Reasoning 
* notebooks/03_agentic_approach.ipynb â†’ Agentic Approach

## ðŸ“Š Results Summary

|   **Approach**       | **Average Score** |
|----------------------|-------------------|
| Few-Shot Prompting   |       0.5090      |
| ReAct Reasoning      |       0.3891      |
| Agentic Approach     |       0.4602      |

